import cv2
from ultralytics import YOLO

# ================= C·∫§U H√åNH TR·ª∞C TI·∫æP T·∫†I ƒê√ÇY =================
MODEL_PATH = "C:/Users/khanh/OneDrive/Desktop/Violation Detect/Detection Web/assets/model/best_yolo12s_seg.pt"         # ƒê∆∞·ªùng d·∫´n file model (.pt)
VIDEO_PATH = "C:/Users/khanh/OneDrive/Desktop/Violation Detect/Detection Web/assets/video/test_2.mp4"  # ƒê∆∞·ªùng d·∫´n video c·∫ßn test
OUTPUT_PATH = "output.mp4"     # T√™n video k·∫øt qu·∫£ xu·∫•t ra
CONF_THRESHOLD = 0.5           # ƒê·ªô tin c·∫≠y
IMG_SIZE = 1280                # K√≠ch th∆∞·ªõc x·ª≠ l√Ω
# ===============================================================

def detect_video():
    # 1. T·∫£i model
    print(f"üîÑ ƒêang t·∫£i model: {MODEL_PATH}...")
    try:
        model = YOLO(MODEL_PATH)
    except Exception as e:
        print(f"‚ùå L·ªói: {e}")
        return

    # 2. M·ªü video ƒë·∫ßu v√†o
    cap = cv2.VideoCapture(VIDEO_PATH)
    if not cap.isOpened():
        print(f"‚ùå Kh√¥ng th·ªÉ m·ªü video: {VIDEO_PATH}")
        return

    # L·∫•y th√¥ng s·ªë video
    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))

    # 3. Kh·ªüi t·∫°o b·ªô ghi video (VideoWriter)
    # ƒê·ªãnh d·∫°ng mp4v cho file .mp4
    out = cv2.VideoWriter(OUTPUT_PATH, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))

    print("üé• B·∫Øt ƒë·∫ßu x·ª≠ l√Ω video... Nh·∫•n 'q' ƒë·ªÉ d·ª´ng s·ªõm.")
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break # H·∫øt video

        # 4. Ch·∫°y nh·∫≠n di·ªán tr√™n t·ª´ng khung h√¨nh
        results = model.predict(
            source=frame,
            conf=CONF_THRESHOLD,
            imgsz=IMG_SIZE,
            retina_masks=True,  # <--- QUAN TR·ªåNG: Ch·ªëng rƒÉng c∆∞a
            verbose=False,      # T·∫Øt log spam tr√™n terminal
            stream=True         # Gi√∫p ti·∫øt ki·ªám b·ªô nh·ªõ khi ch·∫°y video d√†i
        )

        # 5. V·∫Ω k·∫øt qu·∫£
        for result in results:
            annotated_frame = result.plot()
            
            # Ghi khung h√¨nh ƒë√£ v·∫Ω v√†o file output
            out.write(annotated_frame)

            # Hi·ªÉn th·ªã tr·ª±c ti·∫øp (Optional)
            cv2.imshow("YOLO Detection", annotated_frame)

        # Nh·∫•n 'q' ƒë·ªÉ tho√°t
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    # 6. D·ªçn d·∫πp
    cap.release()
    out.release()
    cv2.destroyAllWindows()
    print(f"\n‚úÖ Ho√†n t·∫•t! Video ƒë√£ l∆∞u t·∫°i: {OUTPUT_PATH}")

if __name__ == "__main__":
    detect_video()